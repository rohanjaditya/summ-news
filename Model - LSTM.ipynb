{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee3f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, GRU, TimeDistributed, Attention, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62352f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_clean.csv\")\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee19f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_c = np.array([len(x.split()) for x in df['Content']])\n",
    "len_s = np.array([len(x.split()) for x in df['Summary']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_content = 400\n",
    "max_len_summary = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[np.where(np.logical_and(len_c<=max_len_content, len_s<=max_len_summary))[0]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31181a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d712c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['Content'].values, \n",
    "                                                    df['Summary_clean'].values, \n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=767, \n",
    "                                                    shuffle=True)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, \n",
    "                                                  y_train, \n",
    "                                                  test_size=0.1, \n",
    "                                                  random_state=767, \n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45397774",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "\n",
    "tokenizer_content = Tokenizer()\n",
    "tokenizer_content.fit_on_texts(x_train);\n",
    "\n",
    "x_train = tokenizer_content.texts_to_sequences(x_train)\n",
    "x_val = tokenizer_content.texts_to_sequences(x_val)\n",
    "x_test = tokenizer_content.texts_to_sequences(x_test)\n",
    "\n",
    "x_train= pad_sequences(x_train,  maxlen=max_len_content, padding='post')\n",
    "x_val = pad_sequences(x_val,  maxlen=max_len_content, padding='post')\n",
    "x_test = pad_sequences(x_test,  maxlen=max_len_content, padding='post')\n",
    "\n",
    "et = time.time()\n",
    "print(\"Time taken: {:d} h {:d} min {:.2f} s\".format(int((et - st)/3600), int(((et - st)%3600)/60), ((et - st)%3600)%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de48ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "\n",
    "tokenizer_summary = Tokenizer()\n",
    "tokenizer_summary.fit_on_texts(y_train);\n",
    "\n",
    "y_train = tokenizer_summary.texts_to_sequences(y_train)\n",
    "y_val = tokenizer_summary.texts_to_sequences(y_val)\n",
    "y_test = tokenizer_summary.texts_to_sequences(y_test)\n",
    "\n",
    "y_train= pad_sequences(y_train,  maxlen=max_len_summary, padding='post')\n",
    "y_val = pad_sequences(y_val,  maxlen=max_len_summary, padding='post')\n",
    "y_test = pad_sequences(y_test,  maxlen=max_len_summary, padding='post')\n",
    "\n",
    "et = time.time()\n",
    "print(\"Time taken: {:d} h {:d} min {:.2f} s\".format(int((et - st)/3600), int(((et - st)%3600)/60), ((et - st)%3600)%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_voc = len(tokenizer_content.word_index) + 1\n",
    "y_voc = len(tokenizer_summary.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e8777",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e4a440",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_units = 800\n",
    "embedding_units = 500\n",
    "\n",
    "encoder_input = Input(shape=(max_len_content,))\n",
    "\n",
    "encoder_embedding = Embedding(x_voc, embedding_units, trainable=True, name=\"encoder_emb\")(encoder_input)\n",
    "\n",
    "encoder_lstm1 = LSTM(lstm_units, return_sequences=True, return_state=True, name=\"encoder_lstm1\")\n",
    "encoder_layer1, state_a1, state_c1 = encoder_lstm1(encoder_embedding)\n",
    "\n",
    "encoder_lstm2 = LSTM(lstm_units, return_sequences=True, return_state=True, name=\"encoder_lstm2\")\n",
    "encoder_layer2, state_a2, state_c2 = encoder_lstm2(encoder_layer1)\n",
    "\n",
    "encoder_lstm3 = LSTM(lstm_units, return_sequences=True, return_state=True, name=\"encoder_lstm3\")\n",
    "encoder_layer_last, state_a_last, state_c_last = encoder_lstm3(encoder_layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcdf86b",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None,))\n",
    "\n",
    "decoder_embedding = Embedding(y_voc, embedding_units, trainable=True, name=\"decoder_emb\")\n",
    "decoder_emb_layer = decoder_embedding(decoder_input)\n",
    "\n",
    "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True, name=\"decoder_lstm\")\n",
    "decoder_layer, decoder_state_f, decoder_state_b = decoder_lstm(decoder_emb_layer, initial_state=[state_a_last, state_c_last])\n",
    "\n",
    "attention = Attention()\n",
    "attention_layer = attention([decoder_layer, encoder_layer_last])\n",
    "\n",
    "#attention_pool = GlobalAveragePooling1D()(attention_layer)\n",
    "#decoder_layer_pool = GlobalAveragePooling1D()(decoder_layer)\n",
    "\n",
    "decoder_concat = Concatenate(axis=-1)([decoder_layer, attention_layer])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(y_voc, activation=\"softmax\"))\n",
    "decoder_output = decoder_dense(decoder_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5811242",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"model_weights.h5\" in os.listdir():\n",
    "    model.load_weights(\"model_weights.h5\")\n",
    "\n",
    "else:\n",
    "    history = model.fit(x=[x_train, y_train[:,:-1]], \n",
    "                        y=y_train.reshape(-1, max_len_summary, 1)[:,1:], \n",
    "                        validation_data=([x_val, y_val[:,:-1]], y_val.reshape(-1, max_len_summary, 1)[:,1:]), \n",
    "                        epochs=20, \n",
    "                        callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d174f",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=[encoder_input], outputs=[encoder_layer_last, state_a_last, state_c_last])\n",
    "\n",
    "inference_decoder_input = Input(shape=(max_len_content, lstm_units))\n",
    "decoder_input_a = Input(shape=(lstm_units,))\n",
    "decoder_input_c = Input(shape=(lstm_units,))\n",
    "\n",
    "inference_decoder_emb = decoder_embedding(decoder_input)\n",
    "\n",
    "inference_decoder_layer, inf_state_a, inf_state_c = decoder_lstm(inference_decoder_emb, \n",
    "                                                         initial_state=[decoder_input_a, decoder_input_c])\n",
    "\n",
    "inference_attention = attention([inference_decoder_layer, inference_decoder_input])\n",
    "#inference_attention, shp1 = attention([inference_decoder_input, inference_decoder_layer])\n",
    "\n",
    "inference_concat = Concatenate()([inference_decoder_layer, inference_attention])\n",
    "\n",
    "inference_decoder_output = decoder_dense(inference_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f337fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = Model([decoder_input] + [inference_decoder_input, decoder_input_a, decoder_input_c], \n",
    "                        [inference_decoder_output] + [inf_state_a, inf_state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ebbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"inference_model_weights.h5\" in os.listdir():\n",
    "    inference_model.load_weights(\"inference_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c41cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word_content = tokenizer_content.index_word\n",
    "index_word_summary = tokenizer_summary.index_word\n",
    "word_index_content = tokenizer_content.word_index\n",
    "word_index_summary = tokenizer_summary.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c63816",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word_content = tokenizer_content.index_word\n",
    "index_word_summary = tokenizer_summary.index_word\n",
    "word_index_content = tokenizer_content.word_index\n",
    "word_index_summary = tokenizer_summary.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e7a24f",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44353baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_summary(input_tokens):\n",
    "    \n",
    "    encoder_output, encoder_state_a, encoder_state_c = encoder_model.predict(input_tokens)\n",
    "    \n",
    "    decoder_input_token = np.array([[word_index_summary['start']]])\n",
    "    \n",
    "    flag = False\n",
    "    pred_sentence = \"start\"\n",
    "    \n",
    "    while not flag:\n",
    "        inference_output, inference_a, inference_c = inference_model.predict([decoder_input_token] + [encoder_output, encoder_state_a, encoder_state_c])\n",
    "        \n",
    "        token_idx = np.argmax(inference_output.ravel())\n",
    "        pred_word = index_word_summary[token_idx]\n",
    "        \n",
    "        if pred_word != 'end':\n",
    "            pred_sentence = pred_sentence + \" \" + pred_word\n",
    "            \n",
    "        if pred_word == \"end\" or len(pred_sentence.split()) >= max_len_summary:\n",
    "            pred_sentence = pred_sentence + \" end\"\n",
    "            flag = True\n",
    "            \n",
    "        decoder_input_token = np.array([[token_idx]])\n",
    "        \n",
    "        encoder_state_a = inference_a\n",
    "        encoder_state_c = inference_c\n",
    "    \n",
    "    return pred_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca1880",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 36\n",
    "print(predict_summary(x_test[i].reshape(1,-1)))\n",
    "print(tokenizer_summary.sequences_to_texts([y_test[i]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
